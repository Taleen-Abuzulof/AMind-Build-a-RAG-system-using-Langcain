
# Building a RAG System with **LangChainÂ +Â Gemini**

*Notebook: **`Buildingâ€¯aâ€¯RAGâ€¯systemâ€¯usingâ€¯Langchainâ€¯andâ€¯Gemini.ipynb`***  
*Session date: 9Â MayÂ 2025*

This repository accompanies an interactive workshop that walks through building a **Retrievalâ€‘Augmented Generation (RAG)** pipeline powered by **GoogleÂ Gemini** and **LangChain**.  
The entire demo lives in a single Jupyter/Colab notebook so you can **run it endâ€‘toâ€‘end** with zero boilerplate.

---

## ğŸ—‚ï¸ Whatâ€™s inside?

| Path | Purpose |
|------|---------|
| `Building a RAG system using Langchain and Gemini.ipynb` | Stepâ€‘byâ€‘step notebook with code cells and miniâ€‘tasks |
| `README.md` | â† you are here |

---

## ğŸš€ Quickâ€‘start

### OptionÂ 1Â â€”Â GoogleÂ Colab (easiest)

1. Upload the notebook to Colab or click **â€œOpen in Colabâ€** from GitHub.  
2. In the first code cell, paste your **Gemini API key** when prompted.  
   ```python
   import os
   os.environ["GOOGLE_API_KEY"] = "yahâ€‘aiâ€‘key"
   ```  
3. Run the notebook topâ€‘toâ€‘bottom â–¶ï¸.

### OptionÂ 2Â â€”Â Local Jupyter

```bash
# Clone & enter
git clone https://github.com/<yourâ€‘handle>/geminiâ€‘ragâ€‘demo.git
cd geminiâ€‘ragâ€‘demo

# Create a virtual env (optional but tidy)
python -m venv .venv && source .venv/bin/activate

# Install requirements
pip install -r requirements.txt      # see list below

# Export your key (fish / PowerShell syntax will differ)
export GOOGLE_API_KEY="yahâ€‘aiâ€‘key"

# Launch Jupyter
jupyter lab  Building\ a\ RAG\ system\ using\ Langchain\ and\ Gemini.ipynb
```

### Minimal `requirements.txt`

```
langchain>=0.1
langchain-community
langchain-core
langchain-google-genai
chromadb
google-generativeai     # pulled in by langchainâ€‘googleâ€‘genai
beautifulsoup4          # HTML parsing for WebBaseLoader
tiktoken                # token counting utilities
```

---

## ğŸ› ï¸ How the notebook builds RAG

| Stage | LangChain component | What happens |
|-------|--------------------|--------------|
| **Load docs** | `WebBaseLoader` + **BeautifulSoup** | Scrapes an article on AI agents |
| **Split text** | `RecursiveCharacterTextSplitter` | Keeps chunks <Â 1â€¯k tokens |
| **Embed** | `GoogleGenerativeAIEmbeddings` (`embeddingâ€‘001`) | Turns chunks â†’ vectors |
| **Index** | **Chroma** | Stores vectors on disk (`./chroma_db`) |
| **Retrieve** | `VectorStoreRetriever` | Cosineâ€‘similar topâ€‘*k* search |
| **Generate** | `ChatGoogleGenerativeAI` (`geminiâ€‘2.0â€‘flash`) | LLM answers with retrieved context |
| **Prompt** | LangChain Hub *â€œragâ€‘promptâ€* | Standard Qâ€‘A template |

---

## ğŸ“ Miniâ€‘tasks inside the notebook

| Task | Skill |
|------|-------|
| **TaskÂ 1** â€“ Install packages & set API keys | Setup |
| **TaskÂ 2** â€“ Inspect document chunks | Text splitting |
| **TaskÂ 3** â€“ Print retrieved docs & their count | Retrieval debugging |
| **TaskÂ 4** â€“ Make *k* configurable instead of fixed | Vectorâ€‘store tuning |
| **TaskÂ 5** â€“ Explain what the *temperature* parameter does | LLM prompting |

Feel free to delete or adapt these challenge cells when you turn the demo into production code.

---

## ğŸ”„ Customisation ideas

* **Swap Gemini for GPTâ€‘4/Together/Anthropic** â€“ just change the `Chat*` & `Embeddings` classes.  
* **Try another vector DB** â€“ FAISS, Pinecone, or Supabase all work via LangChain.  
* **Chunk smarter** â€“ use `TokenTextSplitter` or semantic chunking for long PDFs.  
* **Add a UI** â€“ wrap the `rag_chain` in Streamlit or Gradio for a chat experience.

---

## ğŸ Troubleshooting

| Problem | Fix |
|---------|-----|
| `google.generativeai.types.APIKeyError` | `GOOGLE_API_KEY` missing or incorrect |
| No module named `chromadb` | `pip install chromadb` |
| Output hallucinations | Increase *k*, give more relevant docs, or adjust prompt |

---

## ğŸ“„ License

MIT â€“ free to use, modify, and distribute with attribution.

---

_README generated automatically on 2025-05-09._
